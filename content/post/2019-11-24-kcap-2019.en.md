+++
title = "K-Cap 2019"
date = 2019-11-24T21:09:40+01:00
draft = false
slug = "kcap-2019"

# Tags and categories
# For example, use `tags = []` for no tags, or the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["conference", "California", "Montolo"]
categories = ["events"]

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
# Use `caption` to display an image caption.
#   Markdown linking is allowed, e.g. `caption = "[Image credit](http://example.org)"`.
# Set `preview` to `false` to disable the thumbnail in listings.
[header]
image = ""
caption = ""
preview = true

+++

<!--more-->

The [International Conference on Knowledge Capture](http://www.k-cap.org/2019/index.html) (K-Cap) takes place every two years alternating with the EKAW conference.
This year it was held in Marina Del Rey, CA in the United States.
I traveled directly from New Zealand were [I attended the ISWC conference](https://sven-lieber.org/en/2019/11/05/iswc-2019/) a few weeks earlier.

**What I liked the most**
K-Cap is a single track conference and thus you can't miss any talk because of another one.

**What I didn't like**
It is interesting that K-Cap is not only about Semantic Web stuff but knowledge capturing from a general perspective also including NLP and machine learning.
However, for me some of these talks were hard to grasp and were not directly related to my research.

# SciKnow workshop
On the first day I attended the [Third International Workshop on Capturing Scientific Knowledge (Sciknow 2019)](https://sciknow.github.io/sciknow2019/).
[Yolanda Gil](https://twitter.com/yolandagil) gave a very interesting keynote about the capturing of hypotheses and scenarios in scientific research.
"Hypotheses are not finished after a paper is accepted" she said, the confidence value of the hypothesis changes over time.
New and/or more test subjects might be available later.
Additionally there are also other methods available to evaluate a hypothesis even though some labs might use the same or similar methods *just because they were always used*.

[Allard Oelen](https://www.tib.eu/en/research-development/data-science-digital-libraries/staff/allard-oelen/) talked about the annotation of scientific literature
using crowdsourcing.
It is difficult to find crowd workers qualified for such a task, additionally it is very time consuming as the scientific paper first has to be understood.
Thus Allard and his colleagues aim for a system in which the authors annotate their papers before submitting.
Ideally this should take less than 10 minutes of the authors' time.

# Wikidata tutorial

In the afternoon of the first day I attended the [Linking, Extending, Exploiting and Enhancing Tabular Data with Wikidata](https://knowledgecaptureanddiscovery.github.io/Tutorials/T2WML-K-CAP2019/) tutorial.
I finally learned the basics of Wikidata and its data model which differs from e.g. the one from DBpedia.

