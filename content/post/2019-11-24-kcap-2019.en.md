+++
title = "K-Cap 2019"
date = 2019-11-24T21:09:40+01:00
draft = false
slug = "kcap-2019"

# Tags and categories
# For example, use `tags = []` for no tags, or the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["conference", "California", "Montolo"]
categories = ["events"]

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
# Use `caption` to display an image caption.
#   Markdown linking is allowed, e.g. `caption = "[Image credit](http://example.org)"`.
# Set `preview` to `false` to disable the thumbnail in listings.
[header]
image = "2019-11-24-kcap-cover.jpg"
caption = ""
preview = true

+++

At the end of November 2019 I could visit the sunny California to attend the Conference on Knowledge Capture (K-Cap).
A lot of interesting workshops, tutorials and talks covered topics such as the representation of knowledge in Wikidata,
approaches to transform tabular data to Linked Data, or the representation of scientific literature and processes as Knowledge Graphs.
Additionally I could present our work on MontoloStats. Continue reading for the full trip report!

<!--more-->

The [International Conference on Knowledge Capture](http://www.k-cap.org/2019/index.html) (K-Cap) takes place every two years alternating with the EKAW conference.
This year it was held in Marina Del Rey, CA in the United States.
I traveled directly from New Zealand were [I attended the ISWC conference](https://sven-lieber.org/en/2019/11/05/iswc-2019/) a few weeks earlier.

**What I liked the most**
K-Cap is a single track conference and thus you can't miss any talk because of another one.

**What I didn't like**
It is interesting that K-Cap is not only about Semantic Web stuff but knowledge capturing from a general perspective also including NLP and machine learning.
However, for me some of these talks were hard to grasp and were not directly related to my research.

Talks regarding "Concept embeddings" seemed to be was very present, but since this topic is not too relevant for me I'll skip those :smiley:.
Instead in this post I will mainly focus on talks from the following topics:

* Wikidata
* Languages and approaches to map tabular data to Linked Data
* Knowledge Graphs of scientific practices or literature


# SciKnow workshop
On the first day I attended the [Third International Workshop on Capturing Scientific Knowledge (Sciknow 2019)](https://sciknow.github.io/sciknow2019/).
[Yolanda Gil](https://twitter.com/yolandagil) gave a very interesting keynote about the capturing of hypotheses and scenarios in scientific research.
"Hypotheses are not finished after a paper is accepted" she said, the confidence value of the hypothesis changes over time.
New and/or more test subjects might be available later.
Additionally there are also other methods available to evaluate a hypothesis even though some labs might use the same or similar methods *just because they were always used*.
**I think we should definitely keep track of our hypotheses, methods and results in a systematic fashion: We are scientists in the end, future research from different angles might bring new insights on the current state of knowledge in our community!**

![Yolanda Gil giving a keynote about scientific hypotheses](/img/2019-11-24-kcap-yolanda-gil-keynote.jpg)

[Allard Oelen](https://www.tib.eu/en/research-development/data-science-digital-libraries/staff/allard-oelen/) talked about the annotation of scientific literature
using crowdsourcing to easier compare scientific contributions.
It is difficult to find crowd workers qualified for such a task, additionally it is very time consuming as a scientific paper first has to be understood.
Thus Allard and his colleagues aim for a system in which the authors annotate their papers while submitting.
Ideally this should take less than 10 minutes of the authors' time.
**It is a very intersting approach, but authors might submit only the bare minimum information when provided with a template during paper submission.
I think a gamification approach could here be of help, i.e. showing additionall information based on the Knowledge Graph's statistics,
such as "x% of authors also filled in this form field".**

![Allard Oelen presenting work to easier compare scientific contributions due to annotation](/img/2019-11-24-kcap-allard-oelen-annotation.jpg)

[Oscar Corcho](https://twitter.com/ocorcho) presented ongoing work from [Ana Iglesias Molina](http://mayor2.dia.fi.upm.es/oeg-upm/index.php/en/phdstudents/393-aiglesias/index.html) 
about using spreadsheets to declaratively express Linked Data mappings which then can be translated to the most suitable language.
Starting point of the presented work is the Bio2RDF dataset which contains biomedical knowledge; *how is it generated?*, *is it still up to date?*.
Based on experience in working with different domain experts, spreadsheets have proven to be a good way to represent information.
**It is an interesting approach and distantly reminds me a bit of the [tabOTTR](https://spec.ottr.xyz/tabOTTR/0.3/) representation of the ontology template language [OTTR](https://ottr.xyz/).**

![Oscar Corcho presents the ongoing work of Ana Iglesias Molina about expressing RDF mapping in a tabular structure](/img/2019-11-24-oscar-corcho-choose-mapping-language.jpg)

In classical Linked Open Data, Linked Data is generated and then linked.
[Daniel Garijo](http://dgarijo.com/) presented WDPlus which follows a *link-first* approach, different domain-specific satellites are created around the Wikidata core.

![Daniel Garijo presents the WDPlus framework](/img/2019-11-24-kcap-daniel-garijo-wdplus.jpg)

Some of these satellites might be based on tabular data.
Different languages such as R2RDF and RML exist to transform structured data to RDF.
However, especially in spreadsheets domain experts use a variety of layouts to represent the data which poses challenges.
Therefore WDPlus has the T2WML framework, using YAML to express the transformation from tabular data to Wikidata.
These mappings makes use of YAML which apparently is human-friendlier, some of my colleagues also use YAML to express RML mappings: [YARRRML](http://rml.io/yarrrml/).
**I like the idea of the "link-first" approach, it reminds me of Ontology Engineering where existing classes and properties should be reused as much as possible.
In fact, also the challenges described by Daniel are similar, i.e. the identification of new properties which is currently performed manually by knowledge engineers, namespace issues and inter-satellite links.**


![Daniel Garijo presents the T2WML framework to map tabular data in different layouts to wikidata](/img/2019-11-24-kcap-daniel-garijo-t2wml.jpg)

# Wikidata tutorial

In the afternoon of the first day I attended the [Linking, Extending, Exploiting and Enhancing Tabular Data with Wikidata](https://knowledgecaptureanddiscovery.github.io/Tutorials/T2WML-K-CAP2019/) 
tutorial given by [Daniel Garijo](http://dgarijo.com/) and [Pedro Szekely](https://twitter.com/szeke).
I finally learned the basics of Wikidata and its data model which differs from e.g. the one from DBpedia.

Wikidata is a collection of claims, not necessarily the truth.

![](/img/2019-11-24-kcap-pedro-wikidata-data-model.jpg)

![](/img/2019-11-24-kcap-pedro-wikidata-pluto.jpg)

![](/img/2019-11-24-kcap-pedro-wikidata-hierarchy-stats.jpg)

![](/img/2019-11-24-kcap-daniel-wikidata-rdf.jpg)

Keynote (table reasoning)

![](/img/2019-11-24-kcap-peter-clark-table-knowledge.jpg)

MontoloStats ...

[Cristina-Iulia Bucur](https://twitter.com/larahack) ...

![](/img/2019-11-24-kcap-cristina-review-comments.jpg)

[Binh Vu](https://github.com/binh-vu) ...

![](/img/2019-11-24-kcap-binh-table-layout.jpg)




